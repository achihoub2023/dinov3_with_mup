{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EVA Probe Transform Visualizer\n",
        "\n",
        "This notebook is designed to be executed from inside the [`eva-probe`](https://github.com/MedARC-AI/eva-probe) repository. It demonstrates how to\n",
        "\n",
        "1. Load a handful of raw images from disk.\n",
        "2. Instantiate the image transformations defined by the project configuration.\n",
        "3. Inspect the transformation pipeline.\n",
        "4. Visualize the original and transformed versions of each sample.\n",
        "\n",
        "> **Tip:** Before running the notebook, make sure you have installed the repository's dependencies (see the project's `README.md`) and that any paths configured below point to existing files/directories on your machine.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports\n",
        "\n",
        "This cell gathers all the Python packages we need. The `omegaconf` and `hydra` ecosystem is commonly used in the project for configuration, so we rely on it to parse the transform definitions. Feel free to add extra imports if your environment requires them.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import importlib\n",
        "import inspect\n",
        "import sys\n",
        "from dataclasses import asdict, is_dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, Iterable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "except ImportError as exc:  # pragma: no cover - torch should be available but we fail loudly otherwise\n",
        "    raise ImportError(\"PyTorch is required to run this notebook. Please install it before proceeding.\") from exc\n",
        "\n",
        "try:\n",
        "    from omegaconf import OmegaConf\n",
        "except ImportError as exc:  # pragma: no cover - omegaconf should be available but we fail loudly otherwise\n",
        "    raise ImportError(\n",
        "        \"omegaconf is required to parse the EVA Probe configuration. Install it with `pip install omegaconf`.\"\n",
        "    ) from exc\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure paths\n",
        "\n",
        "Update the variables in the next cell so they match your local checkout. The defaults assume the notebook is saved in the repository's `notebooks/` folder.\n",
        "\n",
        "* `REPO_ROOT`: location of the `eva-probe` repository.\n",
        "* `RAW_IMAGE_ROOT`: directory containing the images you want to inspect.\n",
        "* `TRANSFORM_CONFIG_PATH`: YAML (or `.hydra`) file that defines the transform pipeline you are interested in.\n",
        "* `TRANSFORM_CONFIG_KEY`: dotted path inside the YAML pointing to the transform specification (for example `datamodule.train_transforms`).\n",
        "* `NUM_SAMPLES`: how many images to visualize.\n",
        "* `IMAGE_EXTENSIONS`: file extensions that will be considered when scanning for sample images.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- User editable section ----------------------------------------------------\n",
        "REPO_ROOT = Path.cwd().resolve().parents[0]  # adjust if the notebook is moved elsewhere\n",
        "RAW_IMAGE_ROOT = REPO_ROOT / \"data\" / \"samples\"  # change to the folder that contains your raw images\n",
        "TRANSFORM_CONFIG_PATH = REPO_ROOT / \"configs\" / \"data\" / \"transforms\" / \"default.yaml\"  # adjust to your config file\n",
        "TRANSFORM_CONFIG_KEY = \"transforms.train\"  # dotted path inside the YAML pointing to the transform definition\n",
        "NUM_SAMPLES = 4\n",
        "IMAGE_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "if not REPO_ROOT.exists():\n",
        "    raise FileNotFoundError(f\"REPO_ROOT does not exist: {REPO_ROOT}\")\n",
        "\n",
        "if not RAW_IMAGE_ROOT.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"RAW_IMAGE_ROOT does not exist: {RAW_IMAGE_ROOT}.\n",
        "\"\n",
        "        \"Please update the path so it points to a directory with sample images.\"\n",
        "    )\n",
        "\n",
        "if not TRANSFORM_CONFIG_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"TRANSFORM_CONFIG_PATH does not exist: {TRANSFORM_CONFIG_PATH}.\n",
        "\"\n",
        "        \"Update it so it references a valid EVA Probe transform configuration file.\"\n",
        "    )\n",
        "\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "    print(f\"Added {REPO_ROOT} to PYTHONPATH\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Helpers to instantiate and display transforms\n",
        "\n",
        "The EVA Probe project typically describes transforms with Hydra/OmegaConf objects. The utility functions below convert those dictionaries into actual callables and provide a few quality-of-life helpers for visualisation.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_plain_python(value: Any) -> Any:\n",
        "    \"\"\"Recursively convert OmegaConf nodes, dataclasses, and other containers to plain Python objects.\"\"\"\n",
        "    if value is None:\n",
        "        return None\n",
        "    if isinstance(value, (str, int, float, bool)):\n",
        "        return value\n",
        "    if isinstance(value, Path):\n",
        "        return str(value)\n",
        "    if isinstance(value, dict):\n",
        "        return {k: to_plain_python(v) for k, v in value.items()}\n",
        "    if isinstance(value, (list, tuple, set)):\n",
        "        iterable_type = type(value)\n",
        "        return iterable_type(to_plain_python(v) for v in value)\n",
        "    if is_dataclass(value):\n",
        "        return to_plain_python(asdict(value))\n",
        "    return value\n",
        "\n",
        "\n",
        "def instantiate_from_config(config: Any) -> Any:\n",
        "    \"\"\"Instantiate Python objects from a Hydra-style configuration.\n",
        "\n",
        "    The function understands dictionaries that contain a `_target_` or `target` key. Nested dictionaries and lists are\n",
        "    recursively processed, which allows Compose-style pipelines to be created on the fly.\n",
        "    \"\"\"\n",
        "    if isinstance(config, dict):\n",
        "        keys = {\"_target_\", \"target\"} & config.keys()\n",
        "        if keys:\n",
        "            target_key = keys.pop()\n",
        "            target = config[target_key]\n",
        "            module_path, _, attr_name = target.rpartition('.')\n",
        "            if not module_path:\n",
        "                raise ValueError(f\"Invalid target specification: {target}\")\n",
        "            module = importlib.import_module(module_path)\n",
        "            factory = getattr(module, attr_name)\n",
        "            kwargs = {\n",
        "                k: instantiate_from_config(v)\n",
        "                for k, v in config.items()\n",
        "                if k not in {target_key, \"_target_\"}\n",
        "            }\n",
        "            return factory(**kwargs)\n",
        "        return {k: instantiate_from_config(v) for k, v in config.items()}\n",
        "    if isinstance(config, list):\n",
        "        return [instantiate_from_config(v) for v in config]\n",
        "    return config\n",
        "\n",
        "\n",
        "def flatten_transform(transform: Any) -> list[Any]:\n",
        "    \"\"\"Return a flat list of sub-transforms for inspection purposes.\"\"\"\n",
        "    if transform is None:\n",
        "        return []\n",
        "    if hasattr(transform, 'transforms') and isinstance(transform.transforms, Iterable):\n",
        "        flattened: list[Any] = []\n",
        "        for sub in transform.transforms:\n",
        "            flattened.extend(flatten_transform(sub))\n",
        "        return flattened\n",
        "    return [transform]\n",
        "\n",
        "\n",
        "def apply_transform_to_pil(image: Image.Image, transform: Any) -> Image.Image:\n",
        "    \"\"\"Apply a transform to a PIL image and convert the result back to PIL for display.\"\"\"\n",
        "    if transform is None:\n",
        "        return image\n",
        "\n",
        "    # Try PIL / tensor based transforms first\n",
        "    try:\n",
        "        transformed = transform(image)\n",
        "    except TypeError:\n",
        "        # Albumentations-style API\n",
        "        transformed = transform(image=np.array(image))\n",
        "        if isinstance(transformed, dict) and 'image' in transformed:\n",
        "            transformed = transformed['image']\n",
        "\n",
        "    if isinstance(transformed, Image.Image):\n",
        "        return transformed\n",
        "\n",
        "    if isinstance(transformed, np.ndarray):\n",
        "        array = transformed\n",
        "        if array.ndim == 2:\n",
        "            array = np.stack([array] * 3, axis=-1)\n",
        "        if array.dtype != np.uint8:\n",
        "            if array.max() <= 1.0:\n",
        "                array = np.clip(array, 0.0, 1.0)\n",
        "                array = (array * 255.0).astype(np.uint8)\n",
        "            else:\n",
        "                array = np.clip(array, 0, 255).astype(np.uint8)\n",
        "        return Image.fromarray(array)\n",
        "\n",
        "    if torch.is_tensor(transformed):\n",
        "        tensor = transformed.detach().cpu()\n",
        "        if tensor.ndim == 2:\n",
        "            tensor = tensor.unsqueeze(0)\n",
        "        if tensor.ndim == 3 and tensor.shape[0] in {1, 3}:\n",
        "            tensor = tensor.permute(1, 2, 0)\n",
        "        array = tensor.numpy()\n",
        "        array = np.clip(array, 0.0, 1.0)\n",
        "        array = (array * 255.0).astype(np.uint8)\n",
        "        return Image.fromarray(array)\n",
        "\n",
        "    raise TypeError(\n",
        "        'Unsupported transform output type. Got '\n",
        "        f\"{type(transformed)}; expected PIL.Image.Image, numpy.ndarray, or torch.Tensor.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def describe_transform(transform: Any) -> None:\n",
        "    \"\"\"Print a readable description of the transform pipeline.\"\"\"\n",
        "    flattened = flatten_transform(transform)\n",
        "    print('Transform pipeline:')\n",
        "    for idx, sub in enumerate(flattened, start=1):\n",
        "        qualname = sub.__class__.__name__ if not inspect.isfunction(sub) else sub.__name__\n",
        "        print(f\"  {idx:02d}. {qualname}\")\n",
        "        if hasattr(sub, '__dict__'):\n",
        "            params = {\n",
        "                k: v\n",
        "                for k, v in vars(sub).items()\n",
        "                if not k.startswith('_') and not inspect.ismethod(v) and not inspect.isfunction(v)\n",
        "            }\n",
        "            if params:\n",
        "                for key, value in params.items():\n",
        "                    print(f\"        - {key}: {value}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load the transform configuration\n",
        "\n",
        "This step reads the YAML file, resolves the section that contains the transform specification, and instantiates the actual pipeline. The resulting object is ready to be applied to raw images.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = OmegaConf.load(TRANSFORM_CONFIG_PATH)\n",
        "plain_config = to_plain_python(config)\n",
        "\n",
        "transform_cfg = plain_config\n",
        "for key in TRANSFORM_CONFIG_KEY.split('.'):\n",
        "    if key not in transform_cfg:\n",
        "        raise KeyError(\n",
        "            f\"Could not find the key '{key}' inside the transform configuration.\n",
        "\"\n",
        "            \"Double-check TRANSFORM_CONFIG_KEY or inspect the YAML structure.\"\n",
        "        )\n",
        "    transform_cfg = transform_cfg[key]\n",
        "\n",
        "transform_pipeline = instantiate_from_config(transform_cfg)\n",
        "\n",
        "describe_transform(transform_pipeline)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Gather sample images\n",
        "\n",
        "We now collect a few sample image paths. If your dataset is nested in class-specific subfolders (e.g. ImageNet-style layout), the glob pattern below will still find the images recursively.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_paths = [\n",
        "    path\n",
        "    for extension in IMAGE_EXTENSIONS\n",
        "    for path in sorted(RAW_IMAGE_ROOT.rglob(f\"*{extension}\"))\n",
        "]\n",
        "\n",
        "if not image_paths:\n",
        "    raise RuntimeError(\n",
        "        f\"No images with extensions {IMAGE_EXTENSIONS} were found under {RAW_IMAGE_ROOT}.\n",
        "\"\n",
        "        \"Verify that RAW_IMAGE_ROOT points to the correct location or adjust IMAGE_EXTENSIONS.\"\n",
        "    )\n",
        "\n",
        "sample_paths = image_paths[:NUM_SAMPLES]\n",
        "print(f\"Found {len(image_paths)} image(s); displaying the first {len(sample_paths)} sample(s).\")\n",
        "for idx, path in enumerate(sample_paths, 1):\n",
        "    print(f\"  {idx:02d}. {path}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualise original vs. transformed images\n",
        "\n",
        "The final cell applies the transform pipeline to each sample and displays them side-by-side. If your transforms produce tensors (e.g. normalized PyTorch tensors), they are converted back to displayable images using simple heuristics. Adjust the logic if your pipeline outputs additional data (masks, depth maps, etc.).\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(len(sample_paths), 2, figsize=(10, 4 * len(sample_paths)))\n",
        "if len(sample_paths) == 1:\n",
        "    axes = np.expand_dims(axes, axis=0)\n",
        "\n",
        "for row, image_path in zip(axes, sample_paths):\n",
        "    original = Image.open(image_path).convert('RGB')\n",
        "    transformed = apply_transform_to_pil(original, transform_pipeline)\n",
        "\n",
        "    row[0].imshow(original)\n",
        "    row[0].set_title(f\"Original\n",
        "{image_path.name}\")\n",
        "    row[0].axis('off')\n",
        "\n",
        "    row[1].imshow(transformed)\n",
        "    row[1].set_title('Transformed')\n",
        "    row[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}